"""
RAG ì±—ë´‡ - ì‹¬ë¦¬ ë‰´ìŠ¤ ê²€ìƒ‰ (ì •ë‹µ ë²„ì „)
======================================
ì‹¤í–‰: streamlit run rag_chatbot.py

ì‹¬ë¦¬ ê´€ë ¨ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” RAG ì±—ë´‡
"""

import streamlit as st
import pandas as pd
import numpy as np
import re
import math
import os
from pathlib import Path
from collections import Counter
from dataclasses import dataclass
from typing import Optional

# === í˜ì´ì§€ ì„¤ì • ===
st.set_page_config(
    page_title="RAG ì±—ë´‡ - ì‹¬ë¦¬ ë‰´ìŠ¤",
    page_icon="ğŸ“°",
    layout="wide"
)

# === ì„¤ì • ===
AVATAR_USER = "ğŸ‘¤"
AVATAR_BOT = "ğŸ¤–"

# íŒŒì¼ ê²½ë¡œ ì„¤ì • (ë¡œì»¬ ë° Streamlit Cloud ëª¨ë‘ ì§€ì›)
def get_data_path():
    """ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ê²½ë¡œ
    current_dir = Path(__file__).parent if "__file__" in dir() else Path(".")
    local_path = current_dir / "Practice_data_NewsResult.CSV"

    if local_path.exists():
        return str(local_path)

    # Streamlit Cloudì—ì„œëŠ” í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€
    cloud_path = Path("Practice_data_NewsResult.CSV")
    if cloud_path.exists():
        return str(cloud_path)

    # ìƒëŒ€ ê²½ë¡œ ì‹œë„
    return "Practice_data_NewsResult.CSV"

DATA_PATH = get_data_path()


# === ë°ì´í„° í´ë˜ìŠ¤ ===
@dataclass
class NewsItem:
    """ë‰´ìŠ¤ ë°ì´í„° í´ë˜ìŠ¤"""
    news_id: str
    date: str
    publisher: str
    title: str
    content: str
    url: str
    embedding: Optional[list] = None


# === ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ===
def init_session():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "news_data" not in st.session_state:
        st.session_state.news_data = []
    if "llm" not in st.session_state:
        st.session_state.llm = None
    if "embeddings_ready" not in st.session_state:
        st.session_state.embeddings_ready = False


init_session()


def reset_chat():
    """ëŒ€í™” ì´ˆê¸°í™”"""
    st.session_state.messages = []


def reset_all():
    """ì „ì²´ ì´ˆê¸°í™”"""
    st.session_state.messages = []
    st.session_state.news_data = []
    st.session_state.llm = None
    st.session_state.embeddings_ready = False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_news_data(filepath: str, max_items: int = 100) -> list:
    """CSV íŒŒì¼ì—ì„œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    news_list = []

    # CSV íŒŒì¼ ì½ê¸° (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)
    for encoding in ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']:
        try:
            df = pd.read_csv(filepath, encoding=encoding)
            break
        except (UnicodeDecodeError, LookupError):
            continue
    else:
        # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ì˜¤ë¥˜ ë¬´ì‹œ
        df = pd.read_csv(filepath, encoding='utf-8', encoding_errors='ignore')

    # ìµœëŒ€ max_itemsê°œë§Œ ì‚¬ìš©
    df = df.head(max_items)

    # ê° í–‰ì„ NewsItemìœ¼ë¡œ ë³€í™˜
    for idx, row in df.iterrows():
        news = NewsItem(
            news_id=str(row['ë‰´ìŠ¤ ì‹ë³„ì']),
            date=str(row['ì¼ì']),
            publisher=str(row['ì–¸ë¡ ì‚¬']),
            title=str(row['ì œëª©']),
            content=str(row['ë³¸ë¬¸'])[:500],  # ë³¸ë¬¸ì€ 500ìë¡œ ì œí•œ
            url=str(row['URL'])
        )
        news_list.append(news)

    return news_list


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê´€ë ¨ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_relevant_news(query: str, news_data: list, top_k: int = 5) -> list:
    """ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # BM25 ê²€ìƒ‰ ì‚¬ìš©
    results = bm25_search(query, news_data, top_k)
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë‰´ìŠ¤ ë°ì´í„° í¬ë§·íŒ…
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def format_news_data(news_results: list) -> str:
    """ê²€ìƒ‰ëœ ë‰´ìŠ¤ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    formatted_list = []

    for news, score in news_results:
        formatted = f"ì œëª©: {news.title}, ì–¸ë¡ ì‚¬: {news.publisher}, ë‚ ì§œ: {news.date}\në‚´ìš©: {news.content[:200]}..."
        formatted_list.append(formatted)

    return "\n\n".join(formatted_list)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BM25 ê²€ìƒ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def tokenize(text: str) -> list:
    """ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì €"""
    text = text.lower()
    text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
    tokens = text.split()
    stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were',
                 'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼', 'ë„', 'í•œ', 'ìˆë‹¤', 'í•˜ë‹¤'}
    return [t for t in tokens if t not in stopwords and len(t) > 1]


def bm25_score(query_tokens: list, doc_tokens: list,
               avg_doc_len: float, doc_count: int, doc_freqs: dict,
               k1: float = 1.5, b: float = 0.75) -> float:
    """BM25 ìŠ¤ì½”ì–´ ê³„ì‚°"""
    score = 0.0
    doc_len = len(doc_tokens)
    doc_token_counts = Counter(doc_tokens)

    for token in query_tokens:
        if token not in doc_token_counts:
            continue
        tf = doc_token_counts[token]
        df = doc_freqs.get(token, 0)
        idf = math.log((doc_count - df + 0.5) / (df + 0.5) + 1)
        numerator = tf * (k1 + 1)
        denominator = tf + k1 * (1 - b + b * (doc_len / avg_doc_len))
        score += idf * (numerator / denominator)

    return score


def bm25_search(query: str, news_data: list, top_k: int = 5) -> list:
    """BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    if not news_data:
        return []

    # 1. ì¿¼ë¦¬ í† í°í™”
    query_tokens = tokenize(query)

    # 2. ëª¨ë“  ë‰´ìŠ¤ì˜ í…ìŠ¤íŠ¸ í† í°í™” (ì œëª© + ë‚´ìš©)
    news_tokens_list = [tokenize(news.title + " " + news.content) for news in news_data]

    # 3. ë¬¸ì„œ ë¹ˆë„ ê³„ì‚° (IDFìš©)
    doc_freqs = Counter()
    for tokens in news_tokens_list:
        for token in set(tokens):
            doc_freqs[token] += 1

    # 4. í‰ê·  ë¬¸ì„œ ê¸¸ì´ ê³„ì‚°
    avg_doc_len = sum(len(t) for t in news_tokens_list) / len(news_data)

    # 5. ê° ë‰´ìŠ¤ì— ëŒ€í•´ BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
    results = []
    for news, doc_tokens in zip(news_data, news_tokens_list):
        score = bm25_score(query_tokens, doc_tokens, avg_doc_len, len(news_data), doc_freqs)
        results.append((news, score))

    # 6. ì ìˆ˜ìˆœ ì •ë ¬ ë° ìƒìœ„ top_kê°œ ë°˜í™˜
    results.sort(key=lambda x: x[1], reverse=True)
    return results[:top_k]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Semantic Search
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def cosine_similarity(a: list, b: list) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def semantic_search(query: str, news_data: list, llm, top_k: int = 5) -> list:
    """ì„ë² ë”© ê¸°ë°˜ ì‹œë§¨í‹± ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    if not news_data:
        return []

    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = llm.get_embedding(query)

    # 2. ê° ë‰´ìŠ¤ì™€ ìœ ì‚¬ë„ ê³„ì‚°
    results = []
    for news in news_data:
        if news.embedding:
            sim = cosine_similarity(query_embedding, news.embedding)
            results.append((news, sim))

    # 3. ì ìˆ˜ìˆœ ì •ë ¬ ë° ìƒìœ„ top_kê°œ ë°˜í™˜
    results.sort(key=lambda x: x[1], reverse=True)
    return results[:top_k]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RAG íŒŒì´í”„ë¼ì¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_rag_answer(query: str, news_data: list, llm, use_semantic: bool = False) -> dict:
    """RAG íŒŒì´í”„ë¼ì¸: ê²€ìƒ‰ + ìƒì„±"""

    # 1. ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
    if use_semantic:
        relevant_news = semantic_search(query, news_data, llm, top_k=3)
    else:
        relevant_news = get_relevant_news(query, news_data, top_k=3)

    if not relevant_news:
        return {
            "answer": "ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "sources": []
        }

    # 2. ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
    context = format_news_data(relevant_news)

    # 3. í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ë‹µë³€ ìƒì„±
    prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ê¸°ì‚¬:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""

    answer = llm.generate(prompt)

    return {
        "answer": answer,
        "sources": [(news.title, news.publisher, news.date) for news, _ in relevant_news]
    }


# === LLM í´ë˜ìŠ¤ ===
def get_secret(key: str):
    """API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (í™˜ê²½ë³€ìˆ˜ > Streamlit secrets)"""
    # í™˜ê²½ë³€ìˆ˜ ë¨¼ì € í™•ì¸
    value = os.getenv(key)
    if value:
        return value

    # Streamlit secrets í™•ì¸
    try:
        if hasattr(st, 'secrets') and key in st.secrets:
            return st.secrets[key]
    except Exception:
        pass

    return None


class GeminiLLM:
    def __init__(self, model: str = "gemini-2.0-flash"):
        from google import genai
        api_key = get_secret("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        self.client = genai.Client(api_key=api_key)
        self.model = model
        self.embed_model = "text-embedding-004"

    def generate(self, prompt: str) -> str:
        response = self.client.models.generate_content(model=self.model, contents=prompt)
        return response.text

    def get_embedding(self, text: str) -> list:
        response = self.client.models.embed_content(model=self.embed_model, contents=text)
        return response.embeddings[0].values


class OpenAILLM:
    def __init__(self, model: str = "gpt-4o-mini", embedding_model: str = "text-embedding-3-small"):
        from openai import OpenAI
        api_key = get_secret("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.embedding_model = embedding_model

    def generate(self, prompt: str) -> str:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    def get_embedding(self, text: str) -> list:
        response = self.client.embeddings.create(model=self.embedding_model, input=text)
        return response.data[0].embedding


def create_llm():
    """LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (GOOGLE_API_KEY ìš°ì„ )"""
    if get_secret("GOOGLE_API_KEY"):
        st.sidebar.success("âœ… Gemini API ì‚¬ìš©")
        return GeminiLLM()
    elif get_secret("OPENAI_API_KEY"):
        st.sidebar.success("âœ… OpenAI API ì‚¬ìš©")
        return OpenAILLM()
    else:
        raise ValueError("API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš” (GOOGLE_API_KEY ë˜ëŠ” OPENAI_API_KEY)")


# === ì‚¬ì´ë“œë°” ===
with st.sidebar:
    st.header("ğŸ“° ì‹¬ë¦¬ ë‰´ìŠ¤ RAG")

    st.divider()

    # ë°ì´í„° ë¡œë“œ ì„¤ì •
    max_news = st.slider("ë¡œë“œí•  ë‰´ìŠ¤ ìˆ˜", 10, 200, 50, 10)

    if st.button("ğŸš€ ë°ì´í„° ë¡œë“œ", type="primary", use_container_width=True):
        with st.spinner("ì´ˆê¸°í™” ì¤‘..."):
            try:
                # ë°ì´í„° ë¡œë“œ
                news_data = load_news_data(DATA_PATH, max_items=max_news)
                st.session_state.news_data = news_data

                # LLM ì´ˆê¸°í™”
                llm = create_llm()
                st.session_state.llm = llm

                st.success(f"âœ… {len(news_data)}ê°œ ë‰´ìŠ¤ ë¡œë“œ ì™„ë£Œ!")

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")

    st.divider()

    # ê²€ìƒ‰ ë°©ì‹ ì„ íƒ
    search_method = st.radio(
        "ê²€ìƒ‰ ë°©ì‹",
        ["BM25 (í‚¤ì›Œë“œ)", "Semantic (ì„ë² ë”©)"],
        index=0
    )

    # ì„ë² ë”© ìƒì„± (Semantic Searchìš©)
    if st.session_state.news_data and st.session_state.llm:
        if search_method == "Semantic (ì„ë² ë”©)" and not st.session_state.embeddings_ready:
            if st.button("ğŸ§  ì„ë² ë”© ìƒì„±", use_container_width=True):
                with st.spinner("ì„ë² ë”© ìƒì„± ì¤‘..."):
                    progress = st.progress(0)
                    for i, news in enumerate(st.session_state.news_data):
                        text = news.title + " " + news.content[:200]
                        news.embedding = st.session_state.llm.get_embedding(text)
                        progress.progress((i + 1) / len(st.session_state.news_data))
                    st.session_state.embeddings_ready = True
                    st.success("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!")

    st.divider()

    # ë²„íŠ¼ ì˜ì—­
    col1, col2 = st.columns(2)
    with col1:
        st.button("ğŸ”„ ìƒˆ ëŒ€í™”", on_click=reset_chat, use_container_width=True)
    with col2:
        st.button("ğŸ—‘ï¸ ì „ì²´ ì´ˆê¸°í™”", on_click=reset_all, use_container_width=True)

    # ìƒíƒœ í‘œì‹œ
    if st.session_state.news_data:
        st.success(f"ğŸ“š {len(st.session_state.news_data)}ê°œ ë‰´ìŠ¤ ì¤€ë¹„ë¨")
        if st.session_state.embeddings_ready:
            st.success("ğŸ§  ì„ë² ë”© ì¤€ë¹„ë¨")


# === ë©”ì¸ ì˜ì—­ ===
st.title("ğŸ“° RAG ì±—ë´‡ - ì‹¬ë¦¬ ë‰´ìŠ¤")

st.markdown("""
ì‹¬ë¦¬ ê´€ë ¨ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ ì§ˆë¬¸:**
- "ì •ì‹ ê±´ê°• ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ëŠ”?"
- "ì‹¬ë¦¬ìƒë‹´ íŠ¸ë Œë“œëŠ”?"
- "ìš°ìš¸ì¦ ì¹˜ë£Œ ê´€ë ¨ ë‰´ìŠ¤"
- "ì²­ì†Œë…„ ì‹¬ë¦¬ ë¬¸ì œ"
- "ì§ì¥ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë ¨ ê¸°ì‚¬"
""")

st.divider()

if not st.session_state.news_data:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ë°ì´í„° ë¡œë“œ'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
else:
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ“Š ë¡œë“œëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°"):
        for i, news in enumerate(st.session_state.news_data[:5]):
            st.markdown(f"**{i+1}. {news.title}**")
            st.caption(f"{news.publisher} | {news.date}")
            st.write(news.content[:150] + "...")
            st.divider()

    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"], avatar=msg.get("avatar")):
            st.markdown(msg["content"])
            if msg.get("sources"):
                with st.expander("ğŸ“š ì°¸ì¡° ë‰´ìŠ¤"):
                    for title, publisher, date in msg["sources"]:
                        st.markdown(f"**{title}** ({publisher}, {date})")

    # ì‚¬ìš©ì ì…ë ¥
    if user_input := st.chat_input("ì‹¬ë¦¬ ê´€ë ¨ ë‰´ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”"):
        st.session_state.messages.append({
            "role": "user",
            "content": user_input,
            "avatar": AVATAR_USER
        })
        with st.chat_message("user", avatar=AVATAR_USER):
            st.markdown(user_input)

        with st.chat_message("assistant", avatar=AVATAR_BOT):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    use_semantic = (search_method == "Semantic (ì„ë² ë”©)" and st.session_state.embeddings_ready)

                    result = generate_rag_answer(
                        user_input,
                        st.session_state.news_data,
                        st.session_state.llm,
                        use_semantic=use_semantic
                    )
                    response = result["answer"]
                    sources = result["sources"]

                    st.markdown(response)

                    if sources:
                        with st.expander("ğŸ“š ì°¸ì¡° ë‰´ìŠ¤"):
                            for title, publisher, date in sources:
                                st.markdown(f"**{title}** ({publisher}, {date})")

                except Exception as e:
                    response = f"âš ï¸ ì˜¤ë¥˜: {str(e)}"
                    sources = []
                    st.error(response)

        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "avatar": AVATAR_BOT,
            "sources": sources
        })

        st.rerun()
