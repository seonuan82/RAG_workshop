"""
RAG Workshop - Streamlit UI
============================
ì‹¤í–‰: streamlit run app.py
"""

import streamlit as st
from rag_workshop import (
    Config, Document, Chunk,
    load_korquad_data, create_chunks, create_llm,
    SimpleVectorStore, RAGPipeline, cosine_similarity
)
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="RAG Workshop",
    page_icon="ğŸ”",
    layout="wide"
)

st.title("ğŸ” RAG Workshop")
st.markdown("KorQuAD 2.1 ê¸°ë°˜ RAG ì‹¤ìŠµ")

# ì‚¬ì´ë“œë°” - ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ì²­í¬ ì„¤ì •
    chunk_size = st.slider("ì²­í¬ í¬ê¸°", 200, 1000, 500, 100)
    chunk_overlap = st.slider("ì²­í¬ ì˜¤ë²„ë©", 0, 200, 100, 50)
    top_k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (Top-K)", 1, 10, 3)
    max_documents = st.slider("ë¡œë“œí•  ë¬¸ì„œ ìˆ˜", 10, 100, 50, 10)

    st.divider()

    # API ìƒíƒœ í‘œì‹œ
    st.header("ğŸ”‘ API ìƒíƒœ")
    google_key = os.getenv("GOOGLE_API_KEY") or st.secrets.get("GOOGLE_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")

    if google_key:
        st.success("âœ… Gemini API ì‚¬ìš© ê°€ëŠ¥")
    if openai_key:
        st.success("âœ… OpenAI API ì‚¬ìš© ê°€ëŠ¥")
    if not google_key and not openai_key:
        st.error("âŒ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”")


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "rag" not in st.session_state:
    st.session_state.rag = None
    st.session_state.llm = None  # LLM ê°ì²´ ì €ì¥ (ìˆœìˆ˜ API ë¹„êµìš©)
    st.session_state.documents = None
    st.session_state.chunks = None
    st.session_state.initialized = False


# ì´ˆê¸°í™” ë²„íŠ¼
col1, col2 = st.columns([1, 3])
with col1:
    if st.button("ğŸš€ RAG ì´ˆê¸°í™”", type="primary"):
        with st.spinner("ì´ˆê¸°í™” ì¤‘..."):
            try:
                # Config ì„¤ì •
                config = Config(
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap,
                    top_k=top_k,
                    max_documents=max_documents
                )

                # ë°ì´í„° ë¡œë“œ
                st.info("ğŸ“¥ ë°ì´í„° ë¡œë“œ ì¤‘...")
                documents = load_korquad_data(max_docs=config.max_documents)
                st.session_state.documents = documents

                # ì²­í‚¹
                st.info("âœ‚ï¸ ì²­í‚¹ ì¤‘...")
                chunks = create_chunks(documents, config.chunk_size, config.chunk_overlap)
                st.session_state.chunks = chunks

                # LLM ì´ˆê¸°í™”
                st.info("ğŸ¤– LLM ì´ˆê¸°í™” ì¤‘...")
                llm = create_llm(config)

                # ë²¡í„° ì €ì¥ì†Œ
                vector_store = SimpleVectorStore()

                # RAG íŒŒì´í”„ë¼ì¸
                rag = RAGPipeline(llm, vector_store, config)

                # ì¸ë±ì‹±
                progress_bar = st.progress(0)
                st.info("ğŸ”¢ ì„ë² ë”© ìƒì„± ì¤‘...")

                total = len(chunks)
                for i, chunk in enumerate(chunks):
                    chunk.embedding = llm.get_embedding(chunk.content)
                    progress_bar.progress((i + 1) / total)

                vector_store.add_chunks(chunks)

                st.session_state.rag = rag
                st.session_state.llm = llm  # LLM ì €ì¥
                st.session_state.initialized = True
                st.success(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ! ({len(documents)}ê°œ ë¬¸ì„œ, {len(chunks)}ê°œ ì²­í¬)")

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")

with col2:
    if st.session_state.initialized:
        st.success(f"âœ… RAG ì¤€ë¹„ ì™„ë£Œ | {len(st.session_state.documents)}ê°œ ë¬¸ì„œ | {len(st.session_state.chunks)}ê°œ ì²­í¬")


# íƒ­ êµ¬ì„±
if st.session_state.initialized:
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ ì§ˆë¬¸í•˜ê¸°", "ğŸ“Š ìƒ˜í”Œ í…ŒìŠ¤íŠ¸", "ğŸ”¬ ë¹„êµ ì‹¤í—˜"])

    # íƒ­ 1: ììœ  ì§ˆë¬¸
    with tab1:
        st.subheader("ğŸ’¬ ììœ  ì§ˆë¬¸í•˜ê¸°")

        question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ê¹€ì—°ì•„ì˜ ì¶œìƒì§€ëŠ”?")

        if st.button("ë‹µë³€ ìƒì„±", key="free_query"):
            if question:
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    result = st.session_state.rag.query(question)

                    st.markdown("### ğŸ“ ë‹µë³€")
                    st.write(result["answer"])

                    st.markdown("### ğŸ“š ì°¸ì¡° ë¬¸ì„œ")
                    for i, source in enumerate(result["sources"]):
                        with st.expander(f"{i+1}. {source['title']}"):
                            st.write(source["content"])
            else:
                st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

    # íƒ­ 2: ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ (RAG vs ìˆœìˆ˜ API ë¹„êµ)
    with tab2:
        st.subheader("ğŸ“Š RAG vs ìˆœìˆ˜ API ë¹„êµ")
        st.markdown("**RAG ì‚¬ìš© ì‹œì™€ ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•Œì˜ ë‹µë³€ì„ ë¹„êµí•©ë‹ˆë‹¤.**")

        # ìƒ˜í”Œ ì§ˆë¬¸ ì„ íƒ
        sample_questions = []
        for doc in st.session_state.documents[:10]:
            if doc.questions:
                sample_questions.append({
                    "question": doc.questions[0]["question"],
                    "answer": doc.questions[0]["answer"],
                    "title": doc.title
                })

        if sample_questions:
            selected = st.selectbox(
                "ìƒ˜í”Œ ì§ˆë¬¸ ì„ íƒ:",
                range(len(sample_questions)),
                format_func=lambda i: f"{sample_questions[i]['title']}: {sample_questions[i]['question'][:50]}..."
            )

            st.markdown(f"**ì •ë‹µ (Ground Truth):** `{sample_questions[selected]['answer']}`")

            if st.button("ğŸ”„ ë¹„êµ ì‹¤í–‰", key="compare_rag"):
                question = sample_questions[selected]["question"]
                ground_truth = sample_questions[selected]["answer"]

                col1, col2, col3 = st.columns(3)

                # 1. ì •ë‹µ
                with col1:
                    st.markdown("### ğŸ¯ ì •ë‹µ")
                    st.info(ground_truth)

                # 2. ìˆœìˆ˜ API (RAG ì—†ì´)
                with col2:
                    st.markdown("### ğŸ’¬ ìˆœìˆ˜ API")
                    with st.spinner("ìˆœìˆ˜ API í˜¸ì¶œ ì¤‘..."):
                        pure_prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n\nì§ˆë¬¸: {question}\n\në‹µë³€:"
                        pure_answer = st.session_state.llm.generate(pure_prompt)
                        st.warning(pure_answer)

                        pure_correct = ground_truth.lower() in pure_answer.lower()
                        if pure_correct:
                            st.success("âœ… ì •ë‹µ í¬í•¨")
                        else:
                            st.error("âŒ ì •ë‹µ ë¯¸í¬í•¨")

                # 3. RAG ì‚¬ìš©
                with col3:
                    st.markdown("### ğŸ” RAG ì‚¬ìš©")
                    with st.spinner("RAG ë‹µë³€ ìƒì„± ì¤‘..."):
                        rag_result = st.session_state.rag.query(question)
                        st.success(rag_result["answer"])

                        rag_correct = ground_truth.lower() in rag_result["answer"].lower()
                        if rag_correct:
                            st.success("âœ… ì •ë‹µ í¬í•¨")
                        else:
                            st.error("âŒ ì •ë‹µ ë¯¸í¬í•¨")

                # ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ
                st.markdown("---")
                st.markdown("### ğŸ“š RAGê°€ ì°¸ì¡°í•œ ë¬¸ì„œ")
                for i, source in enumerate(rag_result["sources"]):
                    with st.expander(f"{i+1}. {source['title']}"):
                        st.write(source["content"])

    # íƒ­ 3: ë¹„êµ ì‹¤í—˜
    with tab3:
        st.subheader("ğŸ”¬ Top-K ë¹„êµ ì‹¤í—˜")

        test_question = st.text_input("ë¹„êµí•  ì§ˆë¬¸:", value=sample_questions[0]["question"] if sample_questions else "")

        k_values = st.multiselect("ë¹„êµí•  Top-K ê°’:", [1, 2, 3, 5, 7, 10], default=[1, 3, 5])

        if st.button("ë¹„êµ ì‹¤í–‰", key="compare"):
            if test_question and k_values:
                results = {}

                progress = st.progress(0)
                for i, k in enumerate(k_values):
                    with st.spinner(f"Top-{k} í…ŒìŠ¤íŠ¸ ì¤‘..."):
                        # ì„ì‹œë¡œ top_k ë³€ê²½
                        original_k = st.session_state.rag.config.top_k
                        st.session_state.rag.config.top_k = k

                        result = st.session_state.rag.query(test_question)
                        results[k] = result

                        st.session_state.rag.config.top_k = original_k
                        progress.progress((i + 1) / len(k_values))

                # ê²°ê³¼ í‘œì‹œ
                st.markdown("### ğŸ“Š ê²°ê³¼ ë¹„êµ")

                for k, result in results.items():
                    with st.expander(f"Top-{k} ê²°ê³¼"):
                        st.write(f"**ë‹µë³€:** {result['answer']}")
                        st.write(f"**ì°¸ì¡° ë¬¸ì„œ:** {[s['title'] for s in result['sources']]}")

else:
    st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì • í›„ 'ğŸš€ RAG ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")


# í‘¸í„°
st.divider()
st.caption("RAG Workshop | KorQuAD 2.1 | Gemini / OpenAI")
