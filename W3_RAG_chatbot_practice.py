"""
RAG ì±—ë´‡ ì‹¤ìŠµ íŒŒì¼ - ì‹¬ë¦¬ ë‰´ìŠ¤ ê²€ìƒ‰
====================================
ì‹¤í–‰: streamlit run rag_chatbot_practice.py

ğŸ“ ì‹¤ìŠµ ëª©í‘œ:
1. get_relevant_news() í•¨ìˆ˜ êµ¬í˜„
2. bm25_search() í•¨ìˆ˜ êµ¬í˜„
3. semantic_search() í•¨ìˆ˜ êµ¬í˜„

ğŸ’¡ ë°ì´í„°: Practice_data_NewsResult.CSV (ì‹¬ë¦¬ í‚¤ì›Œë“œ ë‰´ìŠ¤ 1ê°œì›”ì¹˜)

ğŸ” ì˜ˆì‹œ ì§ˆë¬¸:
- "ì •ì‹ ê±´ê°• ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ëŠ”?"
- "ì‹¬ë¦¬ìƒë‹´ íŠ¸ë Œë“œëŠ”?"
- "ìš°ìš¸ì¦ ì¹˜ë£Œ ê´€ë ¨ ë‰´ìŠ¤"
- "ì²­ì†Œë…„ ì‹¬ë¦¬ ë¬¸ì œ"
- "ì§ì¥ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë ¨ ê¸°ì‚¬"
"""

import streamlit as st
import pandas as pd
import numpy as np
import re
import math
import os
from pathlib import Path
from collections import Counter
from dataclasses import dataclass
from typing import Optional

# === í˜ì´ì§€ ì„¤ì • ===
st.set_page_config(
    page_title="RAG ì±—ë´‡ ì‹¤ìŠµ - ì‹¬ë¦¬ ë‰´ìŠ¤",
    page_icon="ğŸ“°",
    layout="wide"
)

# === ì„¤ì • ===
AVATAR_USER = "ğŸ‘¤"
AVATAR_BOT = "ğŸ¤–"
CSV_FILENAME = "Practice_data_NewsResult.CSV"
# GitHub Raw URL (ì €ì¥ì†Œì— CSV íŒŒì¼ ì—…ë¡œë“œ í›„ ì´ URL ìˆ˜ì • í•„ìš”)
GITHUB_CSV_URL = "https://raw.githubusercontent.com/seonuan82/RAG_Workshop/main/Practice_data_NewsResult.CSV"


def get_data_path():
    """ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ë¡œì»¬ > í˜„ì¬ ë””ë ‰í† ë¦¬ > None)"""
    try:
        current_dir = Path(__file__).parent
        local_path = current_dir / CSV_FILENAME
        if local_path.exists():
            return str(local_path)
    except:
        pass
    cloud_path = Path(CSV_FILENAME)
    if cloud_path.exists():
        return str(cloud_path)
    return None  # GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ í•„ìš”


def load_news_from_github(max_items: int = 100) -> list:
    """GitHubì—ì„œ ë‰´ìŠ¤ CSV ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œë“œí•©ë‹ˆë‹¤."""
    import urllib.request
    import io

    st.info(f"ğŸ“¥ GitHubì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")

    try:
        with urllib.request.urlopen(GITHUB_CSV_URL) as response:
            content = response.read()

        st.info(f"ğŸ“¦ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(content):,} bytes")

        # cp949 ì¸ì½”ë”©ìœ¼ë¡œ ë””ì½”ë”© (ì¼ë¶€ ì˜ëª»ëœ ë°”ì´íŠ¸ëŠ” ëŒ€ì²´)
        decoded = content.decode('cp949', errors='replace')
        df = pd.read_csv(io.StringIO(decoded))

        st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ")

        return _parse_news_dataframe(df, max_items)

    except Exception as e:
        st.error(f"âŒ GitHub ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []


def _parse_news_dataframe(df: pd.DataFrame, max_items: int = 100) -> list:
    """DataFrameì„ NewsItem ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (ì œê³µë¨)"""
    news_list = []
    df = df.head(max_items)

    # ì»¬ëŸ¼ëª… ë§¤í•‘ (ë‹¤ì–‘í•œ CSV í¬ë§· ì§€ì›)
    col_mapping = {
        'news_id': ['ë‰´ìŠ¤ ì‹ë³„ì', 'ê¸°ì‚¬ ê³ ìœ ë²ˆí˜¸', 'news_id', 'id'],
        'date': ['ì¼ì', 'date', 'ë‚ ì§œ'],
        'publisher': ['ì–¸ë¡ ì‚¬', 'publisher', 'ë§¤ì²´'],
        'title': ['ì œëª©', 'title'],
        'content': ['ë³¸ë¬¸', 'content', 'ë‚´ìš©'],
        'url': ['URL', 'url', 'ë§í¬']
    }

    def find_column(candidates):
        for col in candidates:
            if col in df.columns:
                return col
        return candidates[0]

    id_col = find_column(col_mapping['news_id'])
    date_col = find_column(col_mapping['date'])
    publisher_col = find_column(col_mapping['publisher'])
    title_col = find_column(col_mapping['title'])
    content_col = find_column(col_mapping['content'])
    url_col = find_column(col_mapping['url'])

    for _, row in df.iterrows():
        try:
            news = NewsItem(
                news_id=str(row.get(id_col, '')),
                date=str(row.get(date_col, '')),
                publisher=str(row.get(publisher_col, '')),
                title=str(row.get(title_col, '')),
                content=str(row.get(content_col, ''))[:500],
                url=str(row.get(url_col, ''))
            )
            news_list.append(news)
        except:
            continue
    return news_list


DATA_PATH = get_data_path()


# === ë°ì´í„° í´ë˜ìŠ¤ ===
@dataclass
class NewsItem:
    """ë‰´ìŠ¤ ë°ì´í„° í´ë˜ìŠ¤"""
    news_id: str
    date: str
    publisher: str
    title: str
    content: str
    url: str
    embedding: Optional[list] = None


# === ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ===
def init_session():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "news_data" not in st.session_state:
        st.session_state.news_data = []
    if "llm" not in st.session_state:
        st.session_state.llm = None
    if "embeddings_ready" not in st.session_state:
        st.session_state.embeddings_ready = False
    if "pending_response" not in st.session_state:
        st.session_state.pending_response = False


init_session()


def reset_chat():
    """ëŒ€í™” ì´ˆê¸°í™”"""
    st.session_state.messages = []


def _parse_news_dataframe(df: pd.DataFrame, max_items: int = 100) -> list:
    """DataFrameì„ NewsItem ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    news_list = []

    # ìµœëŒ€ max_itemsê°œë§Œ ì‚¬ìš©
    df = df.head(max_items)

    # ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘ (ë‹¤ì–‘í•œ CSV í¬ë§· ì§€ì›) -------------------------------------------------- BM25 í•¨ìˆ˜ ë‰´ìŠ¤ í† í°í™” ë•Œ ì°¸ê³ !
    col_mapping = {
        'news_id': ['ë‰´ìŠ¤ ì‹ë³„ì', 'ê¸°ì‚¬ ê³ ìœ ë²ˆí˜¸', 'news_id', 'id'],
        'date': ['ì¼ì', 'date', 'ë‚ ì§œ'],
        'publisher': ['ì–¸ë¡ ì‚¬', 'publisher', 'ë§¤ì²´'],
        'title': ['ì œëª©', 'title'],
        'content': ['ë³¸ë¬¸', 'content', 'ë‚´ìš©'],
        'url': ['URL', 'url', 'ë§í¬']
    }

    def find_column(candidates):
        for col in candidates:
            if col in df.columns:
                return col
        return None  # ì°¾ì§€ ëª»í•¨

    id_col = find_column(col_mapping['news_id'])
    date_col = find_column(col_mapping['date'])
    publisher_col = find_column(col_mapping['publisher'])
    title_col = find_column(col_mapping['title'])
    content_col = find_column(col_mapping['content'])
    url_col = find_column(col_mapping['url'])

    # ì»¬ëŸ¼ ë§¤í•‘ ê²°ê³¼ í‘œì‹œ
    st.info(f"ğŸ” ì»¬ëŸ¼ ë§¤í•‘: news_id={id_col}, date={date_col}, publisher={publisher_col}, title={title_col}, content={content_col}, url={url_col}")

    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    if not title_col or not content_col:
        st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì œëª©={title_col}, ë³¸ë¬¸={content_col}")
        st.error(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
        return []

    # ê° í–‰ì„ NewsItemìœ¼ë¡œ ë³€í™˜
    for _, row in df.iterrows():
        try:
            news = NewsItem(
                news_id=str(row.get(id_col, '')) if id_col else '',
                date=str(row.get(date_col, '')) if date_col else '',
                publisher=str(row.get(publisher_col, '')) if publisher_col else '',
                title=str(row.get(title_col, '')),
                content=str(row.get(content_col, '')),
                url=str(row.get(url_col, '')) if url_col else ''
            )
            news_list.append(news)
        except Exception as e:
            continue

    st.success(f"âœ… {len(news_list)}ê°œ ë‰´ìŠ¤ íŒŒì‹± ì™„ë£Œ")
    return news_list


def load_news_data(filepath: Optional[str] = None, max_items: int = 100) -> list:
    """
    GitHubì—ì„œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        filepath: ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í˜¸í™˜ì„± ìœ ì§€ìš©)
        max_items: ë¡œë“œí•  ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜

    Returns:
        NewsItem ë¦¬ìŠ¤íŠ¸
    """
    # GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ
    return load_news_from_github(max_items)

def format_news_data(news_results: list) -> str:
    """ê²€ìƒ‰ëœ ë‰´ìŠ¤ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    formatted_list = []

    for news, score in news_results:
        formatted = f"ì œëª©: {news.title}\nì–¸ë¡ ì‚¬: {news.publisher}\në‚ ì§œ: {news.date}\në³¸ë¬¸: {news.content}"
        formatted_list.append(formatted)

    return "\n\n---\n\n".join(formatted_list)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ìŠµ 1: BM25 ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def tokenize(text: str) -> list:
    """ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì €"""
    text = text.lower()
    text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
    tokens = text.split()
    stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were',
                 'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼', 'ë„', 'í•œ', 'ìˆë‹¤', 'í•˜ë‹¤'}
    return [t for t in tokens if t not in stopwords and len(t) > 1]


def bm25_score(query_tokens: list, doc_tokens: list,
               avg_doc_len: float, doc_count: int, doc_freqs: dict,
               k1: float = 1.5, b: float = 0.75) -> float:
    """BM25 ìŠ¤ì½”ì–´ ê³„ì‚° (ì´ í•¨ìˆ˜ëŠ” ì œê³µë¨)"""
    score = 0.0
    doc_len = len(doc_tokens)
    doc_token_counts = Counter(doc_tokens)

    for token in query_tokens:
        if token not in doc_token_counts:
            continue
        tf = doc_token_counts[token]
        df = doc_freqs.get(token, 0)
        idf = math.log((doc_count - df + 0.5) / (df + 0.5) + 1)
        numerator = tf * (k1 + 1)
        denominator = tf + k1 * (1 - b + b * (doc_len / avg_doc_len))
        score += idf * (numerator / denominator)

    return score


def bm25_search(query: str, news_data: list, top_k: int = 5) -> list:
    """
    BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        news_data: NewsItem ë¦¬ìŠ¤íŠ¸
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜

    Returns:
        [(NewsItem, score), ...] ë¦¬ìŠ¤íŠ¸

    ğŸ’¡ íŒíŠ¸:
    1. ì¿¼ë¦¬ í† í°í™”: tokenize(query)
    2. ëª¨ë“  ë‰´ìŠ¤ í† í°í™”: [tokenize() for 00 in 000]
    3. ë¬¸ì„œ ë¹ˆë„(doc_freqs) ê³„ì‚°
    4. í‰ê·  ë¬¸ì„œ ê¸¸ì´ ê³„ì‚°
    5. ê° ë‰´ìŠ¤ì— ëŒ€í•´ bm25_score() ê³„ì‚°
    6. ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ top_kê°œ ë°˜í™˜
    """
    if not news_data:
        return []

    # TODO: BM25 ê²€ìƒ‰ êµ¬í˜„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. ì¿¼ë¦¬ í† í°í™”
    #    query_tokens = 00000000
    #
    # 2. ëª¨ë“  ë‰´ìŠ¤ì˜ í…ìŠ¤íŠ¸ í† í°í™” (ì œëª© + ë‚´ìš©)
    #    news_tokens_list = 00000000
    #
    # 3. ë¬¸ì„œ ë¹ˆë„ ê³„ì‚° (IDFìš©)
    #    0000
    #
    # 4. í‰ê·  ë¬¸ì„œ ê¸¸ì´ ê³„ì‚°
    #    avg_doc_len = 000000000
    #
    # 5. ê° ë‰´ìŠ¤ì— ëŒ€í•´ BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
    #    results = []
    #    00000000
    #
    # 6. ì ìˆ˜ìˆœ ì •ë ¬ ë° ìƒìœ„ top_kê°œ ë°˜í™˜
    #    0000000000
    #    return 00000000
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ìŠµ 2: Semantic Search í•¨ìˆ˜ êµ¬í˜„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def cosine_similarity(a: list, b: list) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì´ í•¨ìˆ˜ëŠ” ì œê³µë¨)"""
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def semantic_search(query: str, news_data: list, llm, top_k: int = 5) -> list:
    """
    ì„ë² ë”© ê¸°ë°˜ ì‹œë§¨í‹± ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        news_data: NewsItem ë¦¬ìŠ¤íŠ¸ (embedding í•„ë“œ í•„ìš”)
        llm: LLM ì¸ìŠ¤í„´ìŠ¤ (get_embedding ë©”ì„œë“œ í•„ìš”)
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜

    Returns:
        [(NewsItem, score), ...] ë¦¬ìŠ¤íŠ¸

    ğŸ’¡ íŒíŠ¸:
    1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±: llm.get_embedding(query)
    2. ê° ë‰´ìŠ¤ì˜ ì„ë² ë”©ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    3. ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ top_kê°œ ë°˜í™˜
    """
    if not news_data:
        return []

    # TODO: Semantic Search êµ¬í˜„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    #    query_embedding = 0000000
    #
    # 2. ê° ë‰´ìŠ¤ì™€ ìœ ì‚¬ë„ ê³„ì‚°
    #    results = []
    #    000000000
    #
    # 3. ì ìˆ˜ìˆœ ì •ë ¬ ë° ìƒìœ„ top_kê°œ ë°˜í™˜
    #    000000000
    #    return 00000000
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ìŠµ 3: ê´€ë ¨ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_relevant_news(query: str, news_data: list, top_k: int = 5) -> list:
    """
    ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        news_data: NewsItem ë¦¬ìŠ¤íŠ¸
        top_k: ë°˜í™˜í•  ë‰´ìŠ¤ ìˆ˜

    Returns:
        ê´€ë ¨ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ [(NewsItem, score), ...]

    ğŸ’¡ íŒíŠ¸:
    - bm25_search() ë˜ëŠ” semantic_search() í•¨ìˆ˜ ì‚¬ìš©
    - ê²°ê³¼ë¥¼ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ top_kê°œ ë°˜í™˜
    
    ì¶”ê°€ ì‹¤ìŠµ
    - top_k ìˆ˜ì •í•´ ë³´ê¸°!
    """
    # TODO: ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ êµ¬í˜„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ (bm25_search ë˜ëŠ” semantic_search)
    #    results = 00000000
    #
    # 2. ê²°ê³¼ ë°˜í™˜
    #    return 00000000
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    return []




# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„ íƒ ì‹¤ìŠµ: top_k ë“± RAG íŒŒë¼ë¯¸í„° ìˆ˜ì •í•´ ë³´ê¸°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_rag_answer(query: str, news_data: list, llm) -> dict:
    """RAG íŒŒì´í”„ë¼ì¸: ê²€ìƒ‰ + ìƒì„±"""

    # 1. ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
    relevant_news = get_relevant_news(query, news_data, top_k=3)  # ---------------------- top_k ìˆ˜ì • ê°€ëŠ¥

    if not relevant_news:
        return {
            "answer": "âš ï¸ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”.",
            "sources": []
        }

    # 2. ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
    context = format_news_data(relevant_news)

    if not context:
        return {
            "answer": "âš ï¸ ë‰´ìŠ¤ í¬ë§·íŒ…ì´ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. format_news_data() í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”.",
            "sources": []
        }

    # 3. í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ë‹µë³€ ìƒì„± # --------------------------------------------------------- ì±—ë´‡ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ê°€ëŠ¥
    prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ë‰´ìŠ¤ ê¸°ì‚¬:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""

    answer = llm.generate(prompt)

    return {
        "answer": answer,
        "sources": [(news.title, news.publisher, news.date) for news, _ in relevant_news]
    }


# === LLM í´ë˜ìŠ¤ ===
def get_secret(key: str):
    """API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (í™˜ê²½ë³€ìˆ˜ > Streamlit secrets)"""
    value = os.getenv(key)
    if value:
        return value
    try:
        if hasattr(st, 'secrets') and key in st.secrets:
            return st.secrets[key]
    except Exception:
        pass
    return None


class GeminiLLM:
    def __init__(self, model: str = "gemini-2.5-flash"):
        from google import genai
        api_key = get_secret("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        self.client = genai.Client(api_key=api_key)
        self.model = model
        self.embed_model = "text-embedding-004"

    def generate(self, prompt: str) -> str:
        response = self.client.models.generate_content(model=self.model, contents=prompt)
        return response.text

    def get_embedding(self, text: str) -> list:
        response = self.client.models.embed_content(model=self.embed_model, contents=text)
        return response.embeddings[0].values


class OpenAILLM:
    def __init__(self, model: str = "gpt-5-mini", embedding_model: str = "text-embedding-3-small"):
        from openai import OpenAI
        api_key = get_secret("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.embedding_model = embedding_model

    def generate(self, prompt: str) -> str:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    def get_embedding(self, text: str) -> list:
        response = self.client.embeddings.create(model=self.embedding_model, input=text)
        return response.data[0].embedding


def create_llm():
    """LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (GOOGLE_API_KEY ìš°ì„ )"""
    if get_secret("GOOGLE_API_KEY"):
        st.sidebar.success("âœ… Gemini API ì‚¬ìš©")
        return GeminiLLM()
    elif get_secret("OPENAI_API_KEY"):
        st.sidebar.success("âœ… OpenAI API ì‚¬ìš©")
        return OpenAILLM()
    else:
        raise ValueError("API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš” (GOOGLE_API_KEY ë˜ëŠ” OPENAI_API_KEY)")


# === ì‚¬ì´ë“œë°” ===
with st.sidebar:
    st.header("ğŸ“° ì‹¬ë¦¬ ë‰´ìŠ¤ RAG ì‹¤ìŠµ")

    st.markdown("""
    ### ì‹¤ìŠµ ìˆœì„œ
    1. **get_relevant_news()** - ê²€ìƒ‰
    2. **bm25_search()** - BM25 ê²€ìƒ‰
    3. **semantic_search()** - ì‹œë§¨í‹± ê²€ìƒ‰
    """)

    st.divider()

    # ë°ì´í„° ë¡œë“œ
    max_news = st.slider("ë¡œë“œí•  ë‰´ìŠ¤ ìˆ˜", 10, 200, 50, 10)

    if st.button("ğŸš€ ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸°í™”", type="primary", use_container_width=True):
        with st.spinner("ì´ˆê¸°í™” ì¤‘..."):
            try:
                # ë°ì´í„° ë¡œë“œ
                news_data = load_news_data(max_items=max_news)

                if not news_data:
                    st.warning("âš ï¸ load_news_data() í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì„¸ìš”!")
                else:
                    st.session_state.news_data = news_data

                    # LLM ì´ˆê¸°í™”
                    llm = create_llm()
                    st.session_state.llm = llm

                    st.success(f"âœ… {len(news_data)}ê°œ ë‰´ìŠ¤ ë¡œë“œ ì™„ë£Œ!")

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")

    st.divider()

    # ì„ë² ë”© ìƒì„± (ì„ íƒì‚¬í•­)
    if st.session_state.news_data and st.session_state.llm:
        if st.button("ğŸ§  ì„ë² ë”© ìƒì„± (Semantic Searchìš©)", use_container_width=True):
            with st.spinner("ì„ë² ë”© ìƒì„± ì¤‘..."):
                progress = st.progress(0)
                for i, news in enumerate(st.session_state.news_data):
                    text = news.title + " " + news.content[:200]
                    news.embedding = st.session_state.llm.get_embedding(text)
                    progress.progress((i + 1) / len(st.session_state.news_data))
                st.session_state.embeddings_ready = True
                st.success("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!")

    st.divider()
    st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", on_click=reset_chat, use_container_width=True)

    # ìƒíƒœ í‘œì‹œ
    if st.session_state.news_data:
        st.success(f"ğŸ“š {len(st.session_state.news_data)}ê°œ ë‰´ìŠ¤ ì¤€ë¹„ë¨")
        if st.session_state.embeddings_ready:
            st.success("ğŸ§  ì„ë² ë”© ì¤€ë¹„ë¨")


# === ë©”ì¸ ì˜ì—­ (ì•± UI) ===
st.title("ğŸ“° RAG ì±—ë´‡ ì‹¤ìŠµ - ì‹¬ë¦¬ ë‰´ìŠ¤")

st.markdown("""
### ì‹¤ìŠµ: **ì‹¬ë¦¬ ê´€ë ¨ ë‰´ìŠ¤ ë°ì´í„°**ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ëŠ” ì±—ë´‡ ë§Œë“¤ì–´ ë³´ê¸°.

#### ğŸ“‹ êµ¬í˜„í•´ì•¼ í•  í•¨ìˆ˜ë“¤:
1. `get_relevant_news()` - ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
2. `bm25_search()` - BM25 í‚¤ì›Œë“œ ê²€ìƒ‰
3. `semantic_search()` - ì‹œë§¨í‹± ê²€ìƒ‰

ğŸ’¡ êµ¬ê¸€ ì½”ë©ì„ í™œìš©í•´ì„œ ì‹¤ìŠµí•´ ë³´ì„¸ìš”!

#### ğŸ” ì±—ë´‡ì—ê²Œ ë¬¼ì–´ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ì˜ˆì‹œ:
- "ì •ì‹ ê±´ê°• ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ëŠ”?"
- "ì‹¬ë¦¬ìƒë‹´ íŠ¸ë Œë“œëŠ”?"
- "ìš°ìš¸ì¦ ì¹˜ë£Œ ê´€ë ¨ ë‰´ìŠ¤"
- "ì²­ì†Œë…„ ì‹¬ë¦¬ ë¬¸ì œ"
- "ì§ì¥ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë ¨ ê¸°ì‚¬"
- "ì‹¬ë¦¬ì¹˜ë£Œì‚¬ ê´€ë ¨ ì •ì±…"
""")

st.divider()

if not st.session_state.news_data:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸°í™”'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
else:
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ“Š ë¡œë“œëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°"):
        for i, news in enumerate(st.session_state.news_data[:5]):
            st.markdown(f"**{i+1}. {news.title}**")
            st.caption(f"{news.publisher} | {news.date}")
            st.write(news.content[:150] + "...")
            st.divider()

    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ)
    chat_container = st.container(height=500)
    with chat_container:
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"], avatar=msg.get("avatar")):
                st.markdown(msg["content"])
                if msg.get("sources"):
                    with st.expander("ğŸ“š ì°¸ì¡° ë‰´ìŠ¤"):
                        for title, publisher, date in msg["sources"]:
                            st.markdown(f"**{title}** ({publisher}, {date})")

        # ì‘ë‹µ ìƒì„± ì¤‘ì¸ ê²½ìš° (ì»¨í…Œì´ë„ˆ ì•ˆì—ì„œ ì²˜ë¦¬)
        if st.session_state.pending_response:
            last_user_input = st.session_state.messages[-1]["content"]
            with st.chat_message("assistant", avatar=AVATAR_BOT):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        result = generate_rag_answer(
                            last_user_input,
                            st.session_state.news_data,
                            st.session_state.llm
                        )
                        response = result["answer"]
                        sources = result["sources"]

                    except Exception as e:
                        response = f"âš ï¸ ì˜¤ë¥˜: {str(e)}"
                        sources = []

            st.session_state.messages.append({
                "role": "assistant",
                "content": response,
                "avatar": AVATAR_BOT,
                "sources": sources
            })
            st.session_state.pending_response = False
            st.rerun()

    # ìë™ ìŠ¤í¬ë¡¤ (ìƒˆ ë©”ì‹œì§€ ì…ë ¥ ì‹œ)
    if st.session_state.messages:
        st.components.v1.html(
            """
            <script>
                const chatContainers = window.parent.document.querySelectorAll('[data-testid="stVerticalBlockBorderWrapper"]');
                chatContainers.forEach(container => {
                    const scrollable = container.querySelector('[data-testid="stVerticalBlock"]');
                    if (scrollable && scrollable.scrollHeight > scrollable.clientHeight) {
                        scrollable.scrollTop = scrollable.scrollHeight;
                    }
                });
            </script>
            """,
            height=0
        )

    # ì‚¬ìš©ì ì…ë ¥
    if user_input := st.chat_input("ì‹¬ë¦¬ ê´€ë ¨ ë‰´ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”"):
        st.session_state.messages.append({
            "role": "user",
            "content": user_input,
            "avatar": AVATAR_USER
        })
        st.session_state.pending_response = True
        st.rerun()
