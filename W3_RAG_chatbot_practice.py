"""
RAG ì±—ë´‡ ì‹¤ìŠµ íŒŒì¼ - ì‹¬ë¦¬ ë‰´ìŠ¤ ê²€ìƒ‰
====================================
ì‹¤í–‰: streamlit run rag_chatbot_practice.py

ğŸ“ ì‹¤ìŠµ ëª©í‘œ:
1. ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
2. get_relevant_news() í•¨ìˆ˜ êµ¬í˜„ (C1M1 ìŠ¤íƒ€ì¼)
3. format_news_data() í•¨ìˆ˜ êµ¬í˜„ (C1M1 ìŠ¤íƒ€ì¼)
4. bm25_search() í•¨ìˆ˜ êµ¬í˜„ (C1M2 ìŠ¤íƒ€ì¼)
5. semantic_search() í•¨ìˆ˜ êµ¬í˜„ (C1M2 ìŠ¤íƒ€ì¼)

ğŸ’¡ ë°ì´í„°: Practice_data_NewsResult.CSV (ì‹¬ë¦¬ í‚¤ì›Œë“œ ë‰´ìŠ¤ 3ê°œì›”ì¹˜)

ğŸ” ì˜ˆì‹œ ì§ˆë¬¸:
- "ì •ì‹ ê±´ê°• ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ëŠ”?"
- "ì‹¬ë¦¬ìƒë‹´ íŠ¸ë Œë“œëŠ”?"
- "ìš°ìš¸ì¦ ì¹˜ë£Œ ê´€ë ¨ ë‰´ìŠ¤"
- "ì²­ì†Œë…„ ì‹¬ë¦¬ ë¬¸ì œ"
- "ì§ì¥ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë ¨ ê¸°ì‚¬"
"""

import streamlit as st
import pandas as pd
import numpy as np
import re
import math
import os
from collections import Counter
from dataclasses import dataclass
from typing import Optional

# === í˜ì´ì§€ ì„¤ì • ===
st.set_page_config(
    page_title="RAG ì±—ë´‡ ì‹¤ìŠµ - ì‹¬ë¦¬ ë‰´ìŠ¤",
    page_icon="ğŸ“°",
    layout="wide"
)

# === ì„¤ì • ===
AVATAR_USER = "ğŸ‘¤"
AVATAR_BOT = "ğŸ¤–"
DATA_PATH = os.path.join(os.path.dirname(__file__), "Practice_data_NewsResult.CSV")


# === ë°ì´í„° í´ë˜ìŠ¤ ===
@dataclass
class NewsItem:
    """ë‰´ìŠ¤ ë°ì´í„° í´ë˜ìŠ¤"""
    date: str
    publisher: str
    title: str
    content: str
    url: str
    embedding: Optional[list] = None


# === ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ===
def init_session():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "news_data" not in st.session_state:
        st.session_state.news_data = []
    if "llm" not in st.session_state:
        st.session_state.llm = None
    if "embeddings_ready" not in st.session_state:
        st.session_state.embeddings_ready = False


init_session()


def reset_chat():
    """ëŒ€í™” ì´ˆê¸°í™”"""
    st.session_state.messages = []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ìŠµ 1: ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_news_data(filepath: str, max_items: int = 100) -> list:
    """CSV íŒŒì¼ì—ì„œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    news_list = []

    # CSV íŒŒì¼ ì½ê¸° (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)
    for encoding in ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']:
        try:
            df = pd.read_csv(filepath, encoding=encoding)
            break
        except (UnicodeDecodeError, LookupError):
            continue
    else:
        # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ì˜¤ë¥˜ ë¬´ì‹œ
        df = pd.read_csv(filepath, encoding='utf-8', encoding_errors='ignore')

    # ìµœëŒ€ max_itemsê°œë§Œ ì‚¬ìš©
    df = df.head(max_items)

    # ê° í–‰ì„ NewsItemìœ¼ë¡œ ë³€í™˜
    for idx, row in df.iterrows():
        news = NewsItem(
            date=str(row['ì¼ì']),
            publisher=str(row['ì–¸ë¡ ì‚¬']),
            title=str(row['ì œëª©']),
            content=str(row['ë³¸ë¬¸'])[:500],  # ë³¸ë¬¸ì€ 500ìë¡œ ì œí•œ
            url=str(row['URL'])
        )
        news_list.append(news)

    return news_list


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ìŠµ 2: ê´€ë ¨ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (C1M1 Exercise 1 ìŠ¤íƒ€ì¼)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_relevant_news(query: str, news_data: list, top_k: int = 5) -> list:
    """
    ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        news_data: NewsItem ë¦¬ìŠ¤íŠ¸
        top_k: ë°˜í™˜í•  ë‰´ìŠ¤ ìˆ˜

    Returns:
        ê´€ë ¨ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ [(NewsItem, score), ...]

    ğŸ’¡ íŒíŠ¸:
    - bm25_search() ë˜ëŠ” semantic_search() í•¨ìˆ˜ ì‚¬ìš©
    - ê²°ê³¼ë¥¼ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ top_kê°œ ë°˜í™˜
    """
    # TODO: ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ êµ¬í˜„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ (bm25_search ë˜ëŠ” semantic_search)
    #    results = bm25_search(query, news_data, top_k)
    #
    # 2. ê²°ê³¼ ë°˜í™˜
    #    return results
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ìŠµ 3: ë‰´ìŠ¤ ë°ì´í„° í¬ë§·íŒ… (C1M1 Exercise 2 ìŠ¤íƒ€ì¼)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def format_news_data(news_results: list) -> str:
    """
    ê²€ìƒ‰ëœ ë‰´ìŠ¤ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.

    Args:
        news_results: [(NewsItem, score), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸

    Returns:
        í¬ë§·íŒ…ëœ ë¬¸ìì—´

    ğŸ’¡ íŒíŠ¸:
    - ê° ë‰´ìŠ¤ì˜ ì œëª©, ë‚ ì§œ, ì–¸ë¡ ì‚¬, ë‚´ìš©ì„ í¬í•¨
    - ì˜ˆì‹œ í˜•ì‹:
      "ì œëª©: {title}, ì–¸ë¡ ì‚¬: {publisher}, ë‚ ì§œ: {date}
       ë‚´ìš©: {content}..."
    """
    # TODO: ë‰´ìŠ¤ í¬ë§·íŒ… êµ¬í˜„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    #    formatted_list = []
    #
    # 2. ê° ë‰´ìŠ¤ í¬ë§·íŒ…
    #    for news, score in news_results:
    #        formatted = f"ì œëª©: {news.title}, ì–¸ë¡ ì‚¬: {news.publisher}, ë‚ ì§œ: {news.date}\në‚´ìš©: {news.content[:200]}..."
    #        formatted_list.append(formatted)
    #
    # 3. ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ë°˜í™˜
    #    return "\n\n".join(formatted_list)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ìŠµ 4: BM25 ê²€ìƒ‰ (C1M2 Exercise 1 ìŠ¤íƒ€ì¼)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def tokenize(text: str) -> list:
    """ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì €"""
    text = text.lower()
    text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
    tokens = text.split()
    stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were',
                 'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼', 'ë„', 'í•œ', 'ìˆë‹¤', 'í•˜ë‹¤'}
    return [t for t in tokens if t not in stopwords and len(t) > 1]


def bm25_score(query_tokens: list, doc_tokens: list,
               avg_doc_len: float, doc_count: int, doc_freqs: dict,
               k1: float = 1.5, b: float = 0.75) -> float:
    """BM25 ìŠ¤ì½”ì–´ ê³„ì‚° (ì´ í•¨ìˆ˜ëŠ” ì œê³µë¨)"""
    score = 0.0
    doc_len = len(doc_tokens)
    doc_token_counts = Counter(doc_tokens)

    for token in query_tokens:
        if token not in doc_token_counts:
            continue
        tf = doc_token_counts[token]
        df = doc_freqs.get(token, 0)
        idf = math.log((doc_count - df + 0.5) / (df + 0.5) + 1)
        numerator = tf * (k1 + 1)
        denominator = tf + k1 * (1 - b + b * (doc_len / avg_doc_len))
        score += idf * (numerator / denominator)

    return score


def bm25_search(query: str, news_data: list, top_k: int = 5) -> list:
    """
    BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        news_data: NewsItem ë¦¬ìŠ¤íŠ¸
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜

    Returns:
        [(NewsItem, score), ...] ë¦¬ìŠ¤íŠ¸

    ğŸ’¡ íŒíŠ¸ (C1M2 Exercise 1 ì°¸ê³ ):
    1. ì¿¼ë¦¬ í† í°í™”: tokenize(query)
    2. ëª¨ë“  ë‰´ìŠ¤ í† í°í™”: [tokenize(news.title + " " + news.content) for news in news_data]
    3. ë¬¸ì„œ ë¹ˆë„(doc_freqs) ê³„ì‚°
    4. í‰ê·  ë¬¸ì„œ ê¸¸ì´ ê³„ì‚°
    5. ê° ë‰´ìŠ¤ì— ëŒ€í•´ bm25_score() ê³„ì‚°
    6. ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ top_kê°œ ë°˜í™˜
    """
    if not news_data:
        return []

    # TODO: BM25 ê²€ìƒ‰ êµ¬í˜„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. ì¿¼ë¦¬ í† í°í™”
    #    query_tokens = tokenize(query)
    #
    # 2. ëª¨ë“  ë‰´ìŠ¤ì˜ í…ìŠ¤íŠ¸ í† í°í™” (ì œëª© + ë‚´ìš©)
    #    news_tokens_list = [tokenize(news.title + " " + news.content) for news in news_data]
    #
    # 3. ë¬¸ì„œ ë¹ˆë„ ê³„ì‚° (IDFìš©)
    #    doc_freqs = Counter()
    #    for tokens in news_tokens_list:
    #        for token in set(tokens):
    #            doc_freqs[token] += 1
    #
    # 4. í‰ê·  ë¬¸ì„œ ê¸¸ì´ ê³„ì‚°
    #    avg_doc_len = sum(len(t) for t in news_tokens_list) / len(news_data)
    #
    # 5. ê° ë‰´ìŠ¤ì— ëŒ€í•´ BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
    #    results = []
    #    for news, doc_tokens in zip(news_data, news_tokens_list):
    #        score = bm25_score(query_tokens, doc_tokens, avg_doc_len, len(news_data), doc_freqs)
    #        results.append((news, score))
    #
    # 6. ì ìˆ˜ìˆœ ì •ë ¬ ë° ìƒìœ„ top_kê°œ ë°˜í™˜
    #    results.sort(key=lambda x: x[1], reverse=True)
    #    return results[:top_k]
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ìŠµ 5: Semantic Search (C1M2 Exercise 2 ìŠ¤íƒ€ì¼)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def cosine_similarity(a: list, b: list) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì´ í•¨ìˆ˜ëŠ” ì œê³µë¨)"""
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def semantic_search(query: str, news_data: list, llm, top_k: int = 5) -> list:
    """
    ì„ë² ë”© ê¸°ë°˜ ì‹œë§¨í‹± ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        news_data: NewsItem ë¦¬ìŠ¤íŠ¸ (embedding í•„ë“œ í•„ìš”)
        llm: LLM ì¸ìŠ¤í„´ìŠ¤ (get_embedding ë©”ì„œë“œ í•„ìš”)
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜

    Returns:
        [(NewsItem, score), ...] ë¦¬ìŠ¤íŠ¸

    ğŸ’¡ íŒíŠ¸ (C1M2 Exercise 2 ì°¸ê³ ):
    1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±: llm.get_embedding(query)
    2. ê° ë‰´ìŠ¤ì˜ ì„ë² ë”©ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    3. ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ top_kê°œ ë°˜í™˜
    """
    if not news_data:
        return []

    # TODO: Semantic Search êµ¬í˜„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    #    query_embedding = llm.get_embedding(query)
    #
    # 2. ê° ë‰´ìŠ¤ì™€ ìœ ì‚¬ë„ ê³„ì‚°
    #    results = []
    #    for news in news_data:
    #        if news.embedding:
    #            sim = cosine_similarity(query_embedding, news.embedding)
    #            results.append((news, sim))
    #
    # 3. ì ìˆ˜ìˆœ ì •ë ¬ ë° ìƒìœ„ top_kê°œ ë°˜í™˜
    #    results.sort(key=lambda x: x[1], reverse=True)
    #    return results[:top_k]
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RAG íŒŒì´í”„ë¼ì¸ (ì œê³µë¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_rag_answer(query: str, news_data: list, llm) -> dict:
    """RAG íŒŒì´í”„ë¼ì¸: ê²€ìƒ‰ + ìƒì„±"""

    # 1. ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
    relevant_news = get_relevant_news(query, news_data, top_k=3)

    if not relevant_news:
        return {
            "answer": "âš ï¸ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”.",
            "sources": []
        }

    # 2. ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
    context = format_news_data(relevant_news)

    if not context:
        return {
            "answer": "âš ï¸ ë‰´ìŠ¤ í¬ë§·íŒ…ì´ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. format_news_data() í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”.",
            "sources": []
        }

    # 3. í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ë‹µë³€ ìƒì„±
    prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ë‰´ìŠ¤ ê¸°ì‚¬:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""

    answer = llm.generate(prompt)

    return {
        "answer": answer,
        "sources": [(news.title, news.publisher, news.date) for news, _ in relevant_news]
    }


# === LLM í´ë˜ìŠ¤ (rag_workshop.pyì—ì„œ ê°€ì ¸ì˜´) ===
def get_secret(key: str):
    try:
        return st.secrets.get(key) or os.getenv(key)
    except:
        return os.getenv(key)


class GeminiLLM:
    def __init__(self, model: str = "gemini-2.5-flash"):
        from google import genai
        api_key = get_secret("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        self.client = genai.Client(api_key=api_key)
        self.model = model
        self.embed_model = "text-embedding-004"

    def generate(self, prompt: str) -> str:
        response = self.client.models.generate_content(model=self.model, contents=prompt)
        return response.text

    def get_embedding(self, text: str) -> list:
        response = self.client.models.embed_content(model=self.embed_model, contents=text)
        return response.embeddings[0].values


class OpenAILLM:
    def __init__(self, model: str = "gpt-5", embedding_model: str = "text-embedding-3-small"):
        from openai import OpenAI
        api_key = get_secret("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.embedding_model = embedding_model

    def generate(self, prompt: str) -> str:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    def get_embedding(self, text: str) -> list:
        response = self.client.embeddings.create(model=self.embedding_model, input=text)
        return response.data[0].embedding


def create_llm():
    if get_secret("GOOGLE_API_KEY"):
        return GeminiLLM()
    elif get_secret("OPENAI_API_KEY"):
        return OpenAILLM()
    else:
        raise ValueError("API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš” (GOOGLE_API_KEY ë˜ëŠ” OPENAI_API_KEY)")


# === ì‚¬ì´ë“œë°” ===
with st.sidebar:
    st.header("ğŸ“° ì‹¬ë¦¬ ë‰´ìŠ¤ RAG ì‹¤ìŠµ")

    st.markdown("""
    ### ì‹¤ìŠµ ìˆœì„œ
    1. **load_news_data()** - ë‰´ìŠ¤ ë¡œë“œ
    2. **get_relevant_news()** - ê²€ìƒ‰
    3. **format_news_data()** - í¬ë§·íŒ…
    4. **bm25_search()** - BM25 ê²€ìƒ‰
    5. **semantic_search()** - ì‹œë§¨í‹± ê²€ìƒ‰
    """)

    st.divider()

    # ë°ì´í„° ë¡œë“œ
    max_news = st.slider("ë¡œë“œí•  ë‰´ìŠ¤ ìˆ˜", 10, 200, 50, 10)

    if st.button("ğŸš€ ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸°í™”", type="primary", use_container_width=True):
        with st.spinner("ì´ˆê¸°í™” ì¤‘..."):
            try:
                # ë°ì´í„° ë¡œë“œ
                news_data = load_news_data(DATA_PATH, max_items=max_news)

                if not news_data:
                    st.warning("âš ï¸ load_news_data() í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì„¸ìš”!")
                else:
                    st.session_state.news_data = news_data

                    # LLM ì´ˆê¸°í™”
                    llm = create_llm()
                    st.session_state.llm = llm

                    st.success(f"âœ… {len(news_data)}ê°œ ë‰´ìŠ¤ ë¡œë“œ ì™„ë£Œ!")

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")

    st.divider()

    # ì„ë² ë”© ìƒì„± (ì„ íƒì‚¬í•­)
    if st.session_state.news_data and st.session_state.llm:
        if st.button("ğŸ§  ì„ë² ë”© ìƒì„± (Semantic Searchìš©)", use_container_width=True):
            with st.spinner("ì„ë² ë”© ìƒì„± ì¤‘..."):
                progress = st.progress(0)
                for i, news in enumerate(st.session_state.news_data):
                    text = news.title + " " + news.content[:200]
                    news.embedding = st.session_state.llm.get_embedding(text)
                    progress.progress((i + 1) / len(st.session_state.news_data))
                st.session_state.embeddings_ready = True
                st.success("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!")

    st.divider()
    st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", on_click=reset_chat, use_container_width=True)

    # ìƒíƒœ í‘œì‹œ
    if st.session_state.news_data:
        st.success(f"ğŸ“š {len(st.session_state.news_data)}ê°œ ë‰´ìŠ¤ ì¤€ë¹„ë¨")
        if st.session_state.embeddings_ready:
            st.success("ğŸ§  ì„ë² ë”© ì¤€ë¹„ë¨")


# === ë©”ì¸ ì˜ì—­ ===
st.title("ğŸ“° RAG ì±—ë´‡ ì‹¤ìŠµ - ì‹¬ë¦¬ ë‰´ìŠ¤")

st.markdown("""
### ì‹¤ìŠµ ì•ˆë‚´

ì´ ì‹¤ìŠµì—ì„œëŠ” **ì‹¬ë¦¬ ê´€ë ¨ ë‰´ìŠ¤ ë°ì´í„°**ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.

#### ğŸ“‹ êµ¬í˜„í•´ì•¼ í•  í•¨ìˆ˜ë“¤:
1. `load_news_data()` - CSVì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
2. `get_relevant_news()` - ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ (C1M1 Exercise 1)
3. `format_news_data()` - ë‰´ìŠ¤ í¬ë§·íŒ… (C1M1 Exercise 2)
4. `bm25_search()` - BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ (C1M2 Exercise 1)
5. `semantic_search()` - ì‹œë§¨í‹± ê²€ìƒ‰ (C1M2 Exercise 2)

#### ğŸ” ì˜ˆì‹œ ì§ˆë¬¸:
- "ì •ì‹ ê±´ê°• ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ëŠ”?"
- "ì‹¬ë¦¬ìƒë‹´ íŠ¸ë Œë“œëŠ”?"
- "ìš°ìš¸ì¦ ì¹˜ë£Œ ê´€ë ¨ ë‰´ìŠ¤"
- "ì²­ì†Œë…„ ì‹¬ë¦¬ ë¬¸ì œ"
- "ì§ì¥ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë ¨ ê¸°ì‚¬"
- "ì‹¬ë¦¬ì¹˜ë£Œì‚¬ ê´€ë ¨ ì •ì±…"

ğŸ’¡ ì™„ì„±ëœ ì½”ë“œëŠ” `rag_chatbot.py`ì™€ `rag_workshop.py`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.
""")

st.divider()

if not st.session_state.news_data:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸°í™”'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
else:
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ“Š ë¡œë“œëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°"):
        for i, news in enumerate(st.session_state.news_data[:5]):
            st.markdown(f"**{i+1}. {news.title}**")
            st.caption(f"{news.publisher} | {news.date}")
            st.write(news.content[:150] + "...")
            st.divider()

    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"], avatar=msg.get("avatar")):
            st.markdown(msg["content"])
            if msg.get("sources"):
                with st.expander("ğŸ“š ì°¸ì¡° ë‰´ìŠ¤"):
                    for title, publisher, date in msg["sources"]:
                        st.markdown(f"**{title}** ({publisher}, {date})")

    # ì‚¬ìš©ì ì…ë ¥
    if user_input := st.chat_input("ì‹¬ë¦¬ ê´€ë ¨ ë‰´ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”"):
        st.session_state.messages.append({
            "role": "user",
            "content": user_input,
            "avatar": AVATAR_USER
        })
        with st.chat_message("user", avatar=AVATAR_USER):
            st.markdown(user_input)

        with st.chat_message("assistant", avatar=AVATAR_BOT):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    result = generate_rag_answer(
                        user_input,
                        st.session_state.news_data,
                        st.session_state.llm
                    )
                    response = result["answer"]
                    sources = result["sources"]

                    st.markdown(response)

                    if sources:
                        with st.expander("ğŸ“š ì°¸ì¡° ë‰´ìŠ¤"):
                            for title, publisher, date in sources:
                                st.markdown(f"**{title}** ({publisher}, {date})")

                except Exception as e:
                    response = f"âš ï¸ ì˜¤ë¥˜: {str(e)}"
                    sources = []
                    st.error(response)

        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "avatar": AVATAR_BOT,
            "sources": sources
        })

        st.rerun()
